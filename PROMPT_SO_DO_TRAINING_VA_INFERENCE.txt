Tạo sơ đồ hoạt động (Mermaid flowchart) chi tiết cho hệ thống gợi ý sản phẩm thương mại điện tử theo ngữ cảnh, bao gồm CẢ quá trình TRAINING và INFERENCE với các yêu cầu sau:

KIẾN TRÚC HỆ THỐNG:
- Frontend (React): Giao diện người dùng
- Backend API (Node.js): Xử lý business logic và gọi ML models  
- ML Models (Python/TensorFlow): 4 mô hình deep learning (ENCM, LNCM, NeuMF, BMF)
- Database: MySQL lưu trữ interactions, products, recommendations, model_runs
- Training Pipeline: Python scripts để train và đánh giá models

PHẦN 1: QUÁ TRÌNH TRAINING (OFFLINE - Thực hiện định kỳ)

1. Thu thập dữ liệu từ Database:
   - Lấy dữ liệu interactions: user_id, product_id, action (view/cart/purchase)
   - Lấy thông tin sản phẩm: category, brand, price
   - Lấy context: time_of_day, season, device_type, category
   - Lấy ratings/comments từ users
   - Tạo label: 1 nếu có interaction tích cực (purchase/cart), 0 nếu không

2. Tiền xử lý dữ liệu (Data Preprocessing):
   - Làm sạch dữ liệu: loại bỏ duplicates, missing values
   - Encode users và items: Sử dụng LabelEncoder để chuyển ID gốc thành index liên tục (0, 1, 2, ...)
   - Encode context features: time_of_day, season, device_type, category
   - Tạo mapping: user_encoder, item_encoder, context_encoder
   - Tính toán số lượng: n_users, n_items, n_contexts

3. Chia dữ liệu (Train/Test Split):
   - Chia dữ liệu thành train set (80%) và test set (20%)
   - Đảm bảo test set có positive samples (label=1)
   - Tạo train_user_pos dictionary để track items đã tương tác của mỗi user

4. Tạo DataLoader:
   - Tạo RatingDataset class: chuyển đổi DataFrame thành Tensor
   - Tạo DataLoader với batch_size (64-1024), shuffle=True cho training
   - Tạo test_loader với shuffle=False cho evaluation

5. Khởi tạo Models (4 mô hình):
   - ENCM: Embedding-based Neural Context Model
     * Input: user_id, item_id, context_features
     * Architecture: User embedding + Item embedding + Context embeddings → Neural layers → Output
   - LNCM: Linear Neural Combination Model
     * Input: user_id, item_id
     * Architecture: Linear part (Matrix Factorization) + Neural part → Combine với alpha weight
   - NeuMF: Neural Matrix Factorization
     * Input: user_id, item_id
     * Architecture: GMF (Generalized Matrix Factorization) + MLP (Multi-Layer Perceptron) → Combine
   - BMF: Bias Matrix Factorization
     * Input: user_id, item_id
     * Architecture: User embedding + Item embedding + User bias + Item bias + Global bias

6. Training Loop (cho mỗi mô hình):
   - Setup: Optimizer (Adam), Loss function (BCELoss), Device (CPU/GPU)
   - Vòng lặp epochs (thường 10-50 epochs):
     * model.train() - chuyển sang chế độ training
     * Duyệt qua từng batch trong train_loader:
       - Forward pass: model(users, items, contexts) → predictions
       - Tính loss: loss = criterion(predictions, labels)
       - Backward pass: loss.backward()
       - Update weights: optimizer.step()
       - Reset gradients: optimizer.zero_grad()
     * Tính average loss cho epoch
     * In ra loss để theo dõi

7. Đánh giá Models (Evaluation):
   - model.eval() - chuyển sang chế độ evaluation
   - Leave-one-out evaluation với sampled negatives:
     * Với mỗi positive (user, item) trong test set
     * Sample 99 negatives từ items chưa tương tác
     * Dự đoán score cho tất cả candidates
     * Rank và tìm vị trí của positive item
   - Tính metrics:
     * Precision@10: Tỷ lệ positive nằm trong top 10
     * MAP@10: Mean Average Precision tại top 10
     * AUC, RMSE, MAE (nếu có)
   - So sánh performance giữa 4 models

8. Lưu Models và Encoders:
   - Lưu model weights: model.save_weights('models/{model_name}_model.h5')
   - Lưu config: n_users, n_items, n_contexts, embedding_dim, hidden_dims → JSON
   - Lưu encoders: pickle.dump(user_encoder, 'training_data/user_encoder.pkl')
   - Lưu context mappings: pickle.dump(context_info, 'training_data/context_features.pkl')
   - Lưu training results: metrics → CSV hoặc pickle

9. Migrate Encoders vào Database:
   - Đọc encoders từ pickle files
   - Insert vào bảng rec_user_encoder (original_id, idx)
   - Insert vào bảng rec_item_encoder (original_id, idx)
   - Insert vào bảng rec_context_mapping (feature_name, original_value, idx)
   - Insert vào bảng rec_context_meta (feature_name, position)

PHẦN 2: QUÁ TRÌNH INFERENCE (ONLINE - Khi user request)

1. User Request: User gửi request từ Frontend (userId, limit)

2. Backend nhận request tại endpoint /api/recommendations/list hoặc /api/recommendations/init

3. Kiểm tra Cache: 
   - Nếu có cache hợp lệ trong bảng recommendations → Trả về kết quả từ database
   - Nếu không → Tiến hành tính toán mới

4. Thu thập dữ liệu người dùng:
   - Lấy lịch sử tương tác: view, cart, purchase từ bảng interactions
   - Lấy thông tin sản phẩm đã tương tác: category, brand
   - Thu thập context hiện tại: time_of_day, season, device_type
   - Lấy ground truth: danh sách sản phẩm đã mua (để đánh giá)

5. Load Models và Encoders:
   - Load encoders từ database (rec_user_encoder, rec_item_encoder)
   - Load context mappings từ database
   - Load model configs từ JSON files
   - Load model weights từ .h5 files
   - Build model architecture dựa trên config

6. Encode User và Items:
   - Encode user_id: user_idx = user_encoder[user_id]
   - Lấy danh sách active items (statusId='S1')
   - Encode item_ids: item_indices = [item_encoder[item_id] for item_id in active_items]
   - Tạo context features từ context hiện tại

7. Gọi Python ML Models (CHẠY SONG SONG):
   - ENCM: 
     * Input: [user_indices, item_indices, context_features]
     * Predict scores cho tất cả items
     * Trả về top-K items có score cao nhất
   - LNCM:
     * Input: [user_indices, item_indices]
     * Predict scores → Top-K
   - NeuMF:
     * Input: [user_indices, item_indices]
     * Predict scores → Top-K
   - BMF:
     * Input: [user_indices, item_indices]
     * Predict scores → Top-K

8. Đánh giá và chọn mô hình tốt nhất:
   - Tính Precision@10 và MAP@10 cho mỗi mô hình (so với ground truth)
   - Sắp xếp mô hình theo MAP@10 (ưu tiên), sau đó Precision@10
   - Chọn mô hình có điểm cao nhất

9. Fallback (nếu Python không khả dụng):
   - Heuristic scoring từ database
   - Tính điểm: Rating(45%) + Rating_count(15%) + Views(15%) + Discount(15%) + Purchase_intent(10%)
   - Mỗi mô hình có trọng số khác nhau
   - Backfill: Thêm sản phẩm cùng category/brand hoặc popular items

10. Lưu Cache: 
    - Lưu vào bảng recommendations (userId, productId, modelName, score)
    - Lưu metrics vào bảng model_runs (userId, modelName, metricsJson, recommendationsJson)

11. Trả về kết quả: 
    - Hydrate thông tin sản phẩm đầy đủ (tên, giá, hình ảnh, ...)
    - Trả về JSON cho Frontend
    - Frontend hiển thị danh sách sản phẩm được gợi ý

YÊU CẦU VẼ SƠ ĐỒ:

1. Phân chia rõ 2 phần:
   - PHẦN TRAINING (Offline): Thực hiện định kỳ, không phụ thuộc vào user request
   - PHẦN INFERENCE (Online): Thực hiện khi có user request

2. Thể hiện luồng dữ liệu:
   - Database → Training Pipeline → Models → Database (lưu models)
   - User Request → Backend → Load Models → Inference → Cache → Response

3. Sử dụng Mermaid flowchart syntax

4. Thể hiện rõ:
   - Các nhánh điều kiện (if/else) cho cache check, fallback
   - Luồng song song (parallel processing) cho 4 mô hình trong inference
   - Vòng lặp training (epochs loop)
   - Quá trình evaluation trong training

5. Màu sắc phân biệt:
   - Training phase: Một màu (ví dụ: xanh lá)
   - Inference phase: Một màu khác (ví dụ: xanh dương)
   - Database operations: Màu khác (ví dụ: vàng)
   - Model operations: Màu khác (ví dụ: đỏ)

6. Có chú thích rõ ràng cho các bước quan trọng

7. Thể hiện được:
   - Training là quá trình offline, không block user requests
   - Inference sử dụng models đã được train sẵn
   - Models được cập nhật định kỳ từ training pipeline

OUTPUT: Code Mermaid flowchart hoàn chỉnh, có thể render ngay, thể hiện đầy đủ cả training và inference process.






